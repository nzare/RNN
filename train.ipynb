{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "train-2017A7PS0139G.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "lRbV0Oyhke8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AJ1grgWYke8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, LSTM, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zwoGUzXZke8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/kaggle/input/nnfl-assignment-2/final_train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_C8TjKAhke8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tgRKZI_Rke8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sw=stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bDIgb0Spke8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stop_lem(review):\n",
        "  \n",
        "  tokens=review.split()\n",
        "  tokens=[token.lower() for token in tokens if token.isalpha() and token not in sw]\n",
        " \n",
        "  lemmatizer=WordNetLemmatizer()\n",
        "  for i in range(len(tokens)):\n",
        "    tokens[i]=lemmatizer.lemmatize(tokens[i])\n",
        "  return ' '.join(tokens)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qg8w8Dgoke8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['desc']=data['desc'].apply(lambda x:stop_lem(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "428WB-C3ke8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = 50000\n",
        "tokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                                   lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(data['desc'].values)\n",
        "X = tokenizer.texts_to_sequences(data['desc'].values)\n",
        "#word_index = tokenizer.word_index\n",
        "#print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "max_length_of_text = 400\n",
        "X = pad_sequences(X, maxlen=max_length_of_text)\n",
        "\n",
        "#print(word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KEnS-loeke8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y = data['rating']\n",
        "y=to_categorical(y)\n",
        "X_train, y_train = X,y\n",
        "print(X_train.shape,y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "To8tjBgLke8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_dim = 200 \n",
        "lstm_out = 100 \n",
        "batch_size =1024\n",
        "\n",
        "inputs = Input((max_length_of_text, ))\n",
        "x = Embedding(num_words, embed_dim)(inputs)    \n",
        "x = LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2, return_sequences=False)(x) # The LSTM transforms the vector sequence into a single vector of size lstm_out, containing information about the entire sequence\n",
        "x = Dense(11,activation='softmax')(x)\n",
        "model = Model(inputs, x)\n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6vXgLZmNke8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dac2zYMLke82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train, batch_size = batch_size, epochs = 15,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',patience=2,min_delta=0.0001)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nBklMgEwke85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"2017A7PS0139G.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}