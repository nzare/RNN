{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluate-2017A7PSS0139G.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBU5AqWekiJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJA0zxjHklNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, LSTM, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v76bw-X3koO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_4HUJ1fkq8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sw=stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD0gOoSqk2GH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stop_lem(review):\n",
        "  \n",
        "  tokens=review.split()\n",
        "  tokens=[token.lower() for token in tokens if token.isalpha() and token not in sw]\n",
        " \n",
        "  lemmatizer=WordNetLemmatizer()\n",
        "  for i in range(len(tokens)):\n",
        "    tokens[i]=lemmatizer.lemmatize(tokens[i])\n",
        "  return ' '.join(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiYoNyAgk6iH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1 = pd.read_csv('/kaggle/input/nnfl-assignment-2/final_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzPi1V33k7H1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1['desc']=data1['desc'].apply(lambda x:stop_lem(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LiHw43PlXwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = 50000\n",
        "tokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                                   lower=True,split=' ')\n",
        "#tokenizer.fit_on_texts(data1['desc'].values)\n",
        "X = tokenizer.texts_to_sequences(data1['desc'].values)\n",
        "#word_index = tokenizer.word_index\n",
        "#print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "max_length_of_text = 400\n",
        "X = pad_sequences(X, maxlen=max_length_of_text)\n",
        "\n",
        "#print(word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7lIqUuJlc9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYeOtZp0ldms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('model-2017A7PS0139G.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6C2xAVoliK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(X_test)\n",
        "y_classes=pred.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byy0fcrvlkEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub=pd.DataFrame({'Id':range(0,len(y_classes)),'Rating':y_classes})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUoJboYSlmpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub.to_csv('2017A7PS0139G.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}